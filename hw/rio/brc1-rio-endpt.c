#include "qemu/osdep.h"
#include "hw/sysbus.h"
#include "hw/register.h"
#include "qemu/bitops.h"
#include "qapi/error.h"
#include "qemu/log.h"
#include "sysemu/dma.h"
#include "hw/fdt_generic_util.h"
#include "hw/rio/brc1-rio-endpt.h"
#include "hw/rio/sm-rio-switch.h"

#include "packet.h"
#include "rio-dev.h"

#define BRC1_RIO_ENDPT_ERR_DEBUG 1

#ifndef BRC1_RIO_ENDPT_ERR_DEBUG
#define BRC1_RIO_ENDPT_ERR_DEBUG 0
#endif

#define CSR_DEBUG BRC1_RIO_ENDPT_ERR_DEBUG

/* The endpoint IP does not implement registers in the whole map,
   only ones up to REG_MAX, but the memory region is for complete configuration
   space defined by Rapid IO spec to be the following size. */
#define IOMEM_REGION_SIZE    0x001000000 /* 16 MB */

#define RIO_NUM_OUT_REGIONS 64 /* Table 119 in User Guide */
#define RIO_NUM_IN_REGIONS  64 /* Table 124 in User Guide */

/* Transaction IDs for requests generated by the hardware */
#define MAP_REQ_TID 1

/* Mesage descriptor fields: see Chapter 7.2 in User Guide.
 * Convention for bit position index: 64 - start - width,
 * so that 'start' value matches the User Guide verbatim.
 */
FIELD(MSG_DESC, PRIO,           64 -  0 -  4,  4)
FIELD(MSG_DESC, INTERRUPT,      64 -  4 -  1,  1)
FIELD(MSG_DESC, FREE,           64 -  5 -  1,  1)
FIELD(MSG_DESC, TTYPE,          64 -  6 -  2,  2)
FIELD(MSG_DESC, DEST_ID,        64 -  8 - 32, 32)
FIELD(MSG_DESC, SRC_ID,         64 -  8 - 32, 32) /* overlaps */
FIELD(MSG_DESC, MSG_LEN,        64 - 40 -  4,  4)
FIELD(MSG_DESC, SEG_SIZE,       64 - 44 -  4,  4)
FIELD(MSG_DESC, LETTER,         64 - 48 -  2,  2)
FIELD(MSG_DESC, MBOX,           64 - 50 -  2,  2)
FIELD(MSG_DESC, MSGSEG_XMBOX,   64 - 52 -  4,  4)

/* These sizes are also implicitly assumed by access calls in the code, but
 * defining this constant anyway just for slightly higher legibility.  */
#define MSG_DESC_HEADER_SIZE    sizeof(uint64_t)
#define MSG_DESC_TIMESTAMP_SIZE sizeof(uint64_t)

/* TODO: take from props? */
#define MSG_PS_MAX_DESCRIPTORS 4
#define MSG_TRGT_MAX_DESCRIPTORS 4

#define ALIGN_MASK(bits) ((1UL << (bits)) - 1)
#define ALIGN(x, bits) \
    (typeof(x))(((uint32_t)(x) + ALIGN_MASK(bits)) & ~ALIGN_MASK(bits))
#define ALIGNED(x, bits) (x == ALIGN(x, bits))

typedef enum RioAddrWidth {
    RIO_ADDR_WIDTH_34_BIT = 34,
    RIO_ADDR_WIDTH_50_BIT = 50,
    RIO_ADDR_WIDTH_66_BIT = 66,
} RioAddrWidth;

/* User Guide Table 120 */
typedef enum MapWriteType {
   MAP_DISABLED = 0b00,
   MAP_NWRITE   = 0b01,
   MAP_NWRITE_R = 0b10,
   MAP_SWRITE   = 0b11,
} MapWriteType;

typedef enum MsgDescType {
    MSG_DESC_INITIATOR_PS,
    MSG_DESC_TARGET,
} MsgDescType;

/* Figure 10 in 7.2.1 in User Guide (in bytes) */
static const uint8_t msg_desc_sizes[] = {
    [MSG_DESC_INITIATOR_PS] = 3 * sizeof(uint64_t),
    [MSG_DESC_TARGET]       = 4 * sizeof(uint64_t),
};
#define MSG_DESC_SIZES_ENTRIES \
    (sizeof(msg_desc_sizes) / sizeof(msg_desc_sizes[0]))
#define MAX_MSG_DESC_SIZE (4 * sizeof(uint64_t)) /* keep synced with above */

static uint8_t msg_desc_size(MsgDescType type)
{
    assert(type < MSG_DESC_SIZES_ENTRIES);
    return msg_desc_sizes[type];
}

/* User Guide Table 120: choice -> number of bits */
enum MapAddrSize {
    MAP_ADDR_SIZE_34_BIT = 0b00,
    MAP_ADDR_SIZE_50_BIT = 0b01,
    MAP_ADDR_SIZE_66_BIT = 0b10,
};
static uint8_t map_addr_size_table[] = {
    [MAP_ADDR_SIZE_34_BIT] = 34,
    [MAP_ADDR_SIZE_50_BIT] = 50,
    [MAP_ADDR_SIZE_66_BIT] = 66,
};
#define MAP_ADDR_SIZE_TABLE_ENTRIES \
    (sizeof(map_addr_size_table) / sizeof(map_addr_size_table[0]))

static uint8_t map_addr_size_to_bits(enum MapAddrSize size_choice)
{
    assert(size_choice < MAP_ADDR_SIZE_TABLE_ENTRIES);
    return map_addr_size_table[size_choice];
}

static rio_devid_t dev_id_mask_table[] = {
    [RIO_TRANSPORT_DEV8]  = 0x000000ff,
    [RIO_TRANSPORT_DEV16] = 0x0000ffff,
    [RIO_TRANSPORT_DEV32] = 0xffffffff,
};
#define DEV_ID_MASK_TABLE_ENTRIES \
    (sizeof(dev_id_mask_table) / sizeof(dev_id_mask_table[0]))

static inline rio_devid_t dev_id_mask(enum rio_transport_type ttype)
{
    assert(ttype < DEV_ID_MASK_TABLE_ENTRIES);
    return dev_id_mask_table[ttype];
}

static void sp_set_tx_state(BRC1RIOEndpt *s, SpTxState state)
{
    s->sp_tx_state = state;
    ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, TX_FIFO_STATE, state);
}

static void sp_set_rx_state(BRC1RIOEndpt *s, SpRxState state)
{
    s->sp_rx_state = state;
    ARRAY_FIELD_DP32(s->regs, IR_SP_RX_STAT, RX_FIFO_STATE, state);
}

static rio_devid_t self_dev_id(BRC1RIOEndpt *s, enum rio_transport_type ttype)
{
    switch (ttype) {
        case RIO_TRANSPORT_DEV8:
            return ARRAY_FIELD_EX32(s->regs, B_DEV_ID, BASE_DEVICE_ID);
        case RIO_TRANSPORT_DEV16:
            return ARRAY_FIELD_EX32(s->regs, B_DEV_ID, LARGE_BASE_DEVICE_ID);
        default:
            assert(!"not supported by HW: device IDs > 16 bits");
    }
}

static void toggle_irq(qemu_irq irq)
{
   /* Edge-triggered IRQ, so interrupt controller latches it */
   qemu_set_irq(irq, 1);
   qemu_set_irq(irq, 0);
}

/* Layout of descriptor bytes is big endian */
static uint64_t msg_desc_read_dw(uint8_t *desc, unsigned len, unsigned *pos)
{
    unsigned b;
    uint64_t val = 0;
    uint8_t *addr = desc + *pos;

    assert(*pos + sizeof(uint64_t) <= len);
    for (b = 0; b < sizeof(uint64_t); ++b) {
        val <<= 8;
        val |= addr[b];
    }
    *pos += sizeof(uint64_t);
    return val;
}

static void msg_desc_write_dw(uint8_t *desc, unsigned size, unsigned *pos,
                              uint64_t val)
{
    unsigned b;
    uint8_t *addr = desc + *pos;

    assert(*pos + sizeof(uint64_t) <= size);
    for (b = 0; b < sizeof(uint64_t); ++b) {
        addr[b] = val >> ((sizeof(uint64_t) - 1) * BITS_PER_BYTE);
        val <<= BITS_PER_BYTE;
    }
    *pos += sizeof(uint64_t);
}

static int fill_pkt_from_msg_desc(BRC1RIOEndpt *s, RioPkt *pkt, bool *interrupt,
                                  trgt_addr_t *next_desc_addr,
                                  trgt_addr_t desc_addr, MsgDescType desc_type)
{
    uint8_t desc_buf[MAX_MSG_DESC_SIZE];
    unsigned desc_size = msg_desc_size(desc_type);
    unsigned rd_pos = 0, wr_pos = 0;
    uint64_t hdr;
    trgt_addr_t payload_ptr;
    int rc;

    assert(desc_addr);

    rc = dma_memory_read(s->dma_as, desc_addr, &desc_buf, desc_size);
    if (rc) {
        /* Assuming that the call can only fail due to a target error
        * (like, due to bad address given), not internal Qemu error. */
        qemu_log("RIO: NOTICE: failed to read memory at 0x%lx via DMA port\n",
                 desc_addr);
        return rc;
    }

    hdr = msg_desc_read_dw(desc_buf, desc_size, &rd_pos);

    if (FIELD_EX64(hdr, MSG_DESC, FREE)) {
        qemu_log("RIO: NOTICE: message descriptor not reserved: rc %u\n", rc);
        return 1;
    }

    /* Set the free bit (in private buffer, not in target mem yet) */
    hdr = FIELD_DP64(hdr, MSG_DESC, FREE, 1);
    msg_desc_write_dw(desc_buf, MAX_MSG_DESC_SIZE, &wr_pos, hdr);

    *interrupt = FIELD_EX64(hdr, MSG_DESC, INTERRUPT);

    pkt->prio = FIELD_EX64(hdr, MSG_DESC, PRIO) & ((1 << PKT_FIELD_PRIO) - 1);
    pkt->ttype = FIELD_EX64(hdr, MSG_DESC, TTYPE);
    pkt->src_id = self_dev_id(s, pkt->ttype);
    pkt->dest_id = FIELD_EX64(hdr, MSG_DESC, DEST_ID);

    pkt->ftype = RIO_FTYPE_MSG;

    pkt->msg_len = FIELD_EX64(hdr, MSG_DESC, MSG_LEN) + 1; /* 0->1 */

    uint8_t seg_size_field = FIELD_EX64(hdr, MSG_DESC, SEG_SIZE);
    pkt->seg_size = msg_seg_size(seg_size_field);
    if (pkt->seg_size == MSG_SEG_SIZE_INVALID) {
        qemu_log("RIO: NOTICE: invalid segment size in msg descriptor: %x\n",
                 seg_size_field);
        return 1;
    }

    pkt->mbox = FIELD_EX64(hdr, MSG_DESC, MBOX);
    pkt->letter = FIELD_EX64(hdr, MSG_DESC, LETTER);
    if (pkt->msg_len > 1) {
        pkt->msg_seg = FIELD_EX64(hdr, MSG_DESC, MSGSEG_XMBOX);
        if (pkt->msg_seg >= pkt->msg_len) {
            qemu_log("RIO: NOTICE: invalid msg segment index in msg descriptor: "
                     "%u (>= msg_len = %u)\n", pkt->msg_seg, pkt->msg_len);
            return 2;
        }
    } else {
        pkt->msg_seg = 0;
        pkt->mbox |= FIELD_EX64(hdr, MSG_DESC, MSGSEG_XMBOX) << PKT_FIELD_MBOX;
    }

    payload_ptr = msg_desc_read_dw(desc_buf, desc_size, &rd_pos);
    *next_desc_addr = msg_desc_read_dw(desc_buf, desc_size, &rd_pos);

    assert(pkt->seg_size % sizeof(uint64_t) == 0); /* enforced above */
    pkt->payload_len = pkt->seg_size / sizeof(uint64_t);

    assert(pkt->seg_size <= RIO_MAX_PAYLOAD_SIZE);
    rc = dma_memory_read(s->dma_as, payload_ptr,
                         pkt->payload, pkt->seg_size);
    if (rc) {
        qemu_log("RIO: NOTICE: fault while reading payload data at %lx\n",
                 payload_ptr);
        return 3;
    }

    /* Write modified header back */
    rc = dma_memory_write(s->dma_as, desc_addr, desc_buf, MSG_DESC_HEADER_SIZE);
    if (rc) {
        qemu_log("RIO: NOTICE: fault while writing header to 0x%lx\n",
                 desc_addr);
        return rc;
    }
    return 0;
}

static int fill_msg_desc_from_pkt(BRC1RIOEndpt *s, trgt_addr_t desc_addr,
                                  bool *interrupt, trgt_addr_t *next_desc_ptr,
                                  RioPkt *pkt)
{
    uint8_t desc_buf[MAX_MSG_DESC_SIZE];
    const int desc_size = msg_desc_size(MSG_DESC_TARGET);
    trgt_addr_t payload_addr;
    uint64_t hdr;
    unsigned rd_pos = 0, wr_pos = 0, ts_pos;
    int rc;

    assert(desc_addr);

    rc = dma_memory_read(s->dma_as, desc_addr, desc_buf, desc_size);
    if (rc) {
        qemu_log("RIO: fault while reading RX MSG descriptor from 0x%lx\r\n",
                 desc_addr);
        return rc;
    }

    hdr = msg_desc_read_dw(desc_buf, desc_size, &rd_pos);

    *interrupt = FIELD_EX64(hdr, MSG_DESC, INTERRUPT);

    assert(!FIELD_EX64(hdr, MSG_DESC, FREE)); /* TODO: target SW error */
    hdr = FIELD_DP64(hdr, MSG_DESC, FREE, 1); /* release to SW */

    hdr = FIELD_DP64(hdr, MSG_DESC, PRIO, pkt->prio);
    hdr = FIELD_DP64(hdr, MSG_DESC, TTYPE, pkt->ttype);
    hdr = FIELD_DP64(hdr, MSG_DESC, SRC_ID, pkt->src_id);
    hdr = FIELD_DP64(hdr, MSG_DESC, MSG_LEN, pkt->msg_len - 1); /* 0->1 */
    hdr = FIELD_DP64(hdr, MSG_DESC, SEG_SIZE,
                     msg_seg_size_field(pkt->seg_size));
    hdr = FIELD_DP64(hdr, MSG_DESC, MBOX, pkt->mbox & 0b11);
    hdr = FIELD_DP64(hdr, MSG_DESC, LETTER, pkt->letter);
    if (pkt->msg_len > 0) {
        hdr = FIELD_DP64(hdr, MSG_DESC, MSGSEG_XMBOX, pkt->msg_seg);
    } else {
        hdr = FIELD_DP64(hdr, MSG_DESC, MSGSEG_XMBOX,
                         (pkt->mbox >> 2) & 0b1111);
    }
    msg_desc_write_dw(desc_buf, desc_size, &wr_pos, hdr);

    payload_addr = msg_desc_read_dw(desc_buf, desc_size, &rd_pos);
    *next_desc_ptr = msg_desc_read_dw(desc_buf, desc_size, &rd_pos);

    ts_pos = wr_pos = rd_pos; /* pointing at timestamp dword */
    msg_desc_write_dw(desc_buf, desc_size, &wr_pos, pkt->timestamp.rcv_time);

    rc = dma_memory_write(s->dma_as, payload_addr,
                          pkt->payload, pkt->seg_size);
    if (rc) {
        qemu_log("RIO: fault while writing RX MSG payload to 0x%lx\r\n",
                 payload_addr);
        return rc;
    }

    /* Write timestamp */
    rc = dma_memory_write(s->dma_as, desc_addr + ts_pos,
                          desc_buf + ts_pos, MSG_DESC_TIMESTAMP_SIZE);
    if (rc) {
        qemu_log("RIO: fault while writing RX msg desc timestamp to 0x%lx\r\n",
                 desc_addr + ts_pos);
        return rc;
    }

    /* Write modified header */
    rc = dma_memory_write(s->dma_as, desc_addr, desc_buf, MSG_DESC_HEADER_SIZE);
    if (rc) {
        qemu_log("RIO: fault while writing RX msg desc header to 0x%lx\r\n",
                 desc_addr);
        return rc;
    }
    return 0;
}

static trgt_addr_t msg_rx_fifo_dequeue(BRC1RIOEndpt *s)
{
    trgt_addr_t desc_addr;

    if (s->msg_rx_fifo_tail == s->msg_rx_fifo_head)
        return 0; /* fifo is empty */

    desc_addr = s->msg_rx_fifo[s->msg_rx_fifo_head];
    s->msg_rx_fifo_head = (s->msg_rx_fifo_head + 1) % MSG_RX_FIFO_SIZE;
    return desc_addr;
}

static int msg_rx_fifo_enqueue(BRC1RIOEndpt *s, trgt_addr_t desc_addr)
{
    unsigned next_tail = (s->msg_rx_fifo_tail + 1) % MSG_RX_FIFO_SIZE;
    if (next_tail == s->msg_rx_fifo_head)
        return -1; /* fifo is full */
    s->msg_rx_fifo[s->msg_rx_fifo_tail] = desc_addr;
    s->msg_rx_fifo_tail = next_tail;
    return 0;
}

static int csr_read32(void *dev, hwaddr addr, uint32_t *value)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(dev);
    RegisterInfo *r;
    unsigned reg_idx = addr / sizeof(uint32_t);
    if (reg_idx >= REG_MAX) {
        qemu_log("RIO: NOTICE: read to register at addr 0x%lx out of range\n",
                 addr);
        return 1;
    }
    r = &s->regs_info[reg_idx];
    *value = register_read(r, ~0, TYPE_BRC1_RIO_ENDPT, CSR_DEBUG);
    return 0;
}

static int csr_write32(void *dev, hwaddr addr, uint32_t value, uint32_t mask)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(dev);
    RegisterInfo *r;
    unsigned reg_idx = addr / sizeof(uint32_t);
    if (reg_idx >= REG_MAX) {
        qemu_log("RIO: NOTICE: write to register at addr 0x%lx out of range\n",
                 addr);
        return 1;
    }
    r = &s->regs_info[reg_idx];
    register_write(r, value, mask, TYPE_BRC1_RIO_ENDPT, CSR_DEBUG);
    return 0;
}

static void brc1_rio_endpt_write(void *opaque, hwaddr addr, uint64_t value,
                      unsigned size)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(opaque);
    int rc;
    uint32_t val32;

    assert(size == sizeof(uint32_t)); /* TODO: implement */
    assert(value >> 32 == 0);

    val32 = (uint32_t)value;
    rc = csr_write32(s, addr, val32, ~0);
    assert(!rc); /* model error: memory region misconfigured */
}

static uint64_t brc1_rio_endpt_read(void *opaque, hwaddr addr, unsigned size)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(opaque);
    int rc;
    uint32_t val32;

    assert(size == sizeof(uint32_t)); /* TODO: implement */

    rc = csr_read32(s, addr, &val32);
    assert(!rc); /* model error: memory region misconfigured */
    return val32;
}

static int transmit_transaction(BRC1RIOEndpt *s, RIOTx *tx)
{
    /* TODO: output port object */
    sm_rio_switch_in(s->rio_switch, s->rio_switch_port_idx, tx);
    return 0;
}

static int transmit_packet(BRC1RIOEndpt *s, const RioPkt *pkt)
{
    uint8_t pkt_buf[PKT_BUF_WORDS * 4]; /* TODO: dynamically allocate only as much as needed */
    unsigned len;

    len = pack_pkt(pkt_buf, sizeof(pkt_buf), pkt);
    log_pkt("EP transmitting packet", pkt_buf, len);

    RIOTx tx = {
        .payload_len = len,
        .payload = (uint8_t *)&pkt_buf[0],
    };
    return transmit_transaction(s, &tx);
}

static int transmit_msg(BRC1RIOEndpt *s, uint64_t desc_addr,
                        MsgDescType desc_type)
{
    int rc;
    RioPkt pkt;
    bool interrupt;
    trgt_addr_t next_desc_addr;
    MsgReq *req;

    assert(desc_addr);

    while (desc_addr) {
        rc = fill_pkt_from_msg_desc(s, &pkt, &interrupt, &next_desc_addr,
                                    desc_addr, desc_type);
        if (rc)
            return rc;

        switch (desc_type) {
            case MSG_DESC_INITIATOR_PS:
                req = &s->msg_req; /* TODO: support more than one */

                assert(req->status != REQ_STATUS_OUTSTANDING);
                req->status = REQ_STATUS_OUTSTANDING;

                req->mbox = pkt.mbox;
                req->letter = pkt.letter;
                req->msg_seg = pkt.msg_seg;

                rc = transmit_packet(s, &pkt);
                if (rc)
                    return rc;

                /* Since everything is synchronous, response got received within
                 * transmit_packet() call above. */

                switch (req->status) {
                    case REQ_STATUS_OUTSTANDING: /* TODO: does HW have timeout, retry? */
                    case REQ_STATUS_ERROR:
                        return 1; /* TODO: how is the failure reported? */
                    case REQ_STATUS_DONE:
                        if (interrupt) {
                            qemu_log("RIO: toggle msg tx irq\n");
                            toggle_irq(s->msg_tx_irq);
                        }
                        break;
                    default:
                        qemu_log("RIO: ERROR: unexpected msg req status: 0x%x\n",
                                 req->status);
                        abort();
                }
                break;
            default:
                abort();
        }

        desc_addr = next_desc_addr;
    }
    return 0;
}

static int handle_maint_access(BRC1RIOEndpt *s, RioPkt *req)
{
	RioPkt resp;

    resp.ttype = req->ttype;
    resp.src_id = self_dev_id(s, resp.ttype);
    resp.dest_id = req->src_id;

    resp.ftype = RIO_FTYPE_MAINT;
    resp.target_tid = req->src_tid;
    resp.hop_count = 0xFF; /* see Spec Part 3 2.5 */

    resp.status = RIO_STATUS_DONE; /* overwritten below in case of error */
    resp.payload_len = 0;

    /* Our register array is fundamentally 32-bit word wide,
       so to process each dword, we must do two accesses. */

    switch (req->transaction) {
        case RIO_TRANS_MAINT_REQ_READ:
            resp.transaction = RIO_TRANS_MAINT_RESP_READ;
            rio_cfg_space_read(s, csr_read32, req, &resp);
            break;
        case RIO_TRANS_MAINT_REQ_WRITE:
            resp.transaction = RIO_TRANS_MAINT_RESP_WRITE;
            rio_cfg_space_write(s, csr_write32, req, &resp);
            break;
        default:
            abort(); /* this handler should not have been called */
    }
    return transmit_packet(s, &resp);
}

static int resolve_map_access_region(BRC1RIOEndpt *s, RioPkt *pkt)
{
    /* Assumes pkt header was unpacked */

    rio_devid_t src_id, src_id_mask;
    unsigned region;
    unsigned nregions = 1 << ARRAY_FIELD_EX32(s->regs, IR_IMAP_CTRL, SUBREGIONS);

    /* TODO: this search is not described explicitly in User Guide, but
     * can't see any other way to find the region, since we can't parse
     * the address from the packet until we know the region (need
     * address width from per-region config register). */
    for (region = 0; region < nregions; ++region) {
        src_id = s->regs[R_IR_IME_0_SRCID + region] & dev_id_mask(pkt->ttype);
        src_id_mask = s->regs[R_IR_IME_0_SRCIDM + region]
                        & dev_id_mask(pkt->ttype);
        if ((src_id & src_id_mask) == (pkt->src_id & src_id_mask)) {
            return region;
        }
    }
    qemu_log("RIO: NOTICE: no region matched for map request\n");
    return -1;
}

static unsigned get_in_map_region_addr_width(BRC1RIOEndpt *s, unsigned region)
{
    uint32_t reg_ctrl = s->regs[R_IR_IME_0_CTRL + region];
    enum MapAddrSize addr_size = FIELD_EX32(reg_ctrl, IR_IME_0_CTRL, ADDR_SIZE);
    return map_addr_size_to_bits(addr_size);
}

static uint64_t get_cfg_space_base_dw_addr(BRC1RIOEndpt *s, unsigned addr_width)
{
    /* See User Guide Table 35 */
    switch (addr_width) {
        case RIO_ADDR_WIDTH_34_BIT:
            return s->regs[R_LCS_BA1] & 0x7fffffff;
        case RIO_ADDR_WIDTH_50_BIT:
            return (((uint64_t)s->regs[R_LCS_BA0] & 0x7fff) << 32) |
                    s->regs[R_LCS_BA1];
        case RIO_ADDR_WIDTH_66_BIT:
            return ((uint64_t)(s->regs[R_LCS_BA0] & 0x7fffffff) << 32) |
                   s->regs[R_LCS_BA1];
        default:
            abort();
    }
}

static void access_bus(BRC1RIOEndpt *s, AccessType access, unsigned region,
                       RioPkt *req, RioPkt *resp)
{
    uint64_t bus_addr; /* byte address */
    int rc;

    /* TODO: User Guide does not describe the translation exactly.
     * Maximum target address width (at least in Qemu) is 64 bits.
     * Maximum RapidIO address is 66 bits. It's not clear how to
     * translate from a 66-bit address into a 64-bit address. */
    assert(req->addr_width < 64);

    bus_addr = ((((uint64_t)s->regs[R_IR_IME_0_ADDR_H + region] << 32) |
                s->regs[R_IR_IME_0_ADDR_L + region])
                    & ~((1ULL << req->addr_width) - 1)) |
                DW_ADDR_TO_BYTE_ADDR(req->dw_addr) | /* assert protects */
                req->dw_offset;

    /* This bus access may be implemented as multiple bus transactions
     * (e.g. accessing 8 bytes on a 32-bit wide bus). The dma_* API
     * takes care of "converting" into access size and alignment
     * required by the destination memory region. I assume that not
     * having a one-to-one mapping between RapidIO requests and bus
     * transactions is fine -- the spec doesn't place any constraints
     * on the internals of the target block in the endpoint. */

    switch (access) {
        case ACCESS_READ:
            rc = dma_memory_read(s->dma_as, bus_addr,
                                 (uint8_t *)resp->payload + req->dw_offset,
                                 req->rdwr_bytes);
            resp->payload_len = div_ceil(req->rdwr_bytes, sizeof(uint64_t));
            break;
        case ACCESS_WRITE:
            rc = dma_memory_write(s->dma_as, bus_addr,
                                  (uint8_t *)req->payload + req->dw_offset,
                                  req->rdwr_bytes);
            break;
    }

    /* The assumtion here is that the only way dma_memory_*() can fail is a
     * fault in the target (as opposed to internal Qemu error). This should
     * hold, since return code from dma_memory_*() is a casted MemTxResult. */
    if (!rc) { /* success */
        resp->status = RIO_STATUS_DONE;
    } else {
        qemu_log("RIO: NOTICE: fault while accessing %lx on local bus\n",
                 bus_addr);
        resp->status = RIO_STATUS_ERROR;
        /* keep going: send response when needed */
    }
}

static int handle_map_access(BRC1RIOEndpt *s, RioPkt *pkt, unsigned region)
{
    RioPkt resp; /* for now allocate even if no response, for code legibility */
    AccessType access;
    uint64_t cfg_dw_base;
    int rc;

    access = pkt->ftype == RIO_FTYPE_READ ? ACCESS_READ : ACCESS_WRITE;

    switch (access) {
        case ACCESS_READ:
            resp.transaction = RIO_TRANS_RESP_WITH_PAYLOAD;
            break;
        case ACCESS_WRITE:
            if (pkt->rdwr_bytes <= sizeof(uint64_t)) {
                assert(pkt->payload_len == 1);
                pkt->payload[0] &= rdwr_dw_mask_from_span(pkt->rdwr_bytes,
                                                          pkt->dw_offset);
            }
            resp.transaction = RIO_TRANS_RESP_WITHOUT_PAYLOAD;
            resp.payload_len = 0;
            break;
    }

    cfg_dw_base = get_cfg_space_base_dw_addr(s, pkt->addr_width);
    if (cfg_dw_base <= pkt->dw_addr && pkt->dw_addr < IOMEM_REGION_SIZE) {
        switch (access) {
            case ACCESS_READ:
                rio_cfg_space_read(s, csr_read32, pkt, &resp);
                break;
            case ACCESS_WRITE:
                rio_cfg_space_write(s, csr_write32, pkt, &resp);
                break;
            default:
                abort();
        }
    } else {
        access_bus(s, access, region, pkt, &resp);
    }

    if (pkt->ftype == RIO_FTYPE_READ ||
        (pkt->ftype == RIO_FTYPE_WRITE &&
         pkt->transaction == RIO_TRANS_WRITE_NWRITE_R)) {

        resp.prio = pkt->prio;
        resp.ttype = pkt->ttype;
        resp.src_id = self_dev_id(s, pkt->ttype);
        resp.dest_id = pkt->src_id;

        resp.ftype = RIO_FTYPE_RESP;
        resp.target_tid = pkt->src_tid;

        rc = transmit_packet(s, &resp);
    } else {
        rc = 0;
    }
    return rc;
}

static int handle_map_response(BRC1RIOEndpt *s, RioPkt *pkt)
{
    MapReq *map_req = &s->map_req; /* hw supports only one outstanding req */
    qemu_log("RIO: map response (for req %p status 0x%x)\n", map_req,
             map_req->status);
    assert(map_req->status == REQ_STATUS_OUTSTANDING);
    map_req->resp_len = pkt->payload_len * sizeof(uint64_t);
    assert(sizeof(map_req->resp_data) >= map_req->resp_len);
    memcpy(map_req->resp_data, pkt->payload, map_req->resp_len);
    map_req->status = pkt->status == RIO_STATUS_DONE ?
                        REQ_STATUS_DONE : REQ_STATUS_ERROR;
    return 0;
}

static int handle_msg(BRC1RIOEndpt *s, RioPkt *pkt)
{
    trgt_addr_t next_desc_addr;
    bool interrupt;
    int rc;
    RioPkt resp;
    enum rio_status status;

    if (!s->msg_rx_desc) {
        s->msg_rx_desc = msg_rx_fifo_dequeue(s);
        qemu_log("RIO: dequeued msg rx desc: @0x%lx\n", s->msg_rx_desc);
        if (!s->msg_rx_desc) {
            qemu_log("RIO: NOTICE: dropped msg packet: no RX msg buffers\n");
            status = RIO_STATUS_ERROR;
            goto ack;
        }
    }
    qemu_log("RIO: msg rx desc: @0x%lx\n", s->msg_rx_desc);
    rc = fill_msg_desc_from_pkt(s, s->msg_rx_desc, &interrupt,
                                &next_desc_addr, pkt);
    if (rc) {
       status = RIO_STATUS_ERROR;
       goto ack;
    }
    status = RIO_STATUS_DONE;
ack:
    resp.prio = pkt->prio;
    resp.ttype = pkt->ttype;
    resp.src_id = self_dev_id(s, pkt->ttype);
    resp.dest_id = pkt->src_id;

    resp.ftype = RIO_FTYPE_RESP;
    resp.transaction = RIO_TRANS_RESP_MSG;
    resp.mbox = pkt->mbox;
    resp.letter = pkt->letter;
    resp.msg_seg = pkt->msg_seg;

    resp.status = status;

    qemu_log("RIO: received msg: sending ack with status %u: from %x to %x\n",
             resp.status, resp.src_id, resp.dest_id);

    rc = transmit_packet(s, &resp);
    if (rc)
        return rc; /* TODO: already filled in rx desc */

    s->msg_rx_desc = next_desc_addr;
    qemu_log("RIO: next msg rx desc: @0x%lx\n", s->msg_rx_desc);

    if (interrupt) {
       qemu_log("RIO: toggle msg rx irq\n");
       toggle_irq(s->msg_rx_irq);
    }
    return 0;
}

static int handle_msg_response(BRC1RIOEndpt *s, RioPkt *pkt)
{
    MsgReq *req = &s->msg_req; /* TODO: support more than one */
    assert(req->status == REQ_STATUS_OUTSTANDING);

    if (req->mbox != pkt->mbox || req->letter != pkt->letter ||
        req->msg_seg != pkt->msg_seg) {
        qemu_log("RIO: NOTICE: unexpected msg response: "
                 "mbox %u (%u) letter %u (%u) seg %u (%u)\n",
                 pkt->mbox, req->mbox, pkt->letter, req->letter,
                 pkt->msg_seg, req->msg_seg);
        return 1; /* TODO: should we deliver to SP interface? */
    }

    req->status = pkt->status == RIO_STATUS_DONE ?
                        REQ_STATUS_DONE : REQ_STATUS_ERROR;
    return 0;
}


static int deliver_to_sw(BRC1RIOEndpt *s, RIOTx *tx)
{
    SpPkt *pkt;

    if (s->sp_rx_fifo_count == SP_RX_FIFO_SIZE) {
        qemu_log("RIO: SP: RX FIFO overflow\n");
        assert(ARRAY_FIELD_EX32(s->regs, IR_SP_RX_STAT, FULL));
        if (ARRAY_FIELD_EX32(s->regs, IR_SP_RX_CTRL, OVERFLOW_MODE_NO_DISCARD)) {
            /* TODO: spec does not document the behavior... overwrite tail? */
            assert(!"no discard on overflow is not implemented");
        } else {
            qemu_log("RIO: SP: RX FIFO overflow: packet discarded\n");
            return 1;
        }
    }

    /* TODO: RX fifo depth > 1 */
    pkt = &s->sp_rx_fifo[0];
    pkt->len = tx->payload_len;
    memcpy(pkt->data, tx->payload, tx->payload_len);
    ++s->sp_rx_fifo_count;

    ARRAY_FIELD_DP32(s->regs, IR_SP_RX_STAT, BUFFERS_FILLED, s->sp_rx_fifo_count);
    if (s->sp_rx_fifo_count == SP_RX_FIFO_SIZE) {
        ARRAY_FIELD_DP32(s->regs, IR_SP_RX_STAT, FULL, 1);
    }

#if 0 /* TODO */
    toggle_irq(s->event_irq, 1);
#endif
    return 0;
}

int brc1_rio_endpt_in(BRC1RIOEndpt *s, RIOTx *tx)
{
    int rc;
    unsigned pos = 0;
    int region;
    rio_devid_t self_id;

    RioPkt pkt; /* TODO: alloc on heap */
    bzero(&pkt, sizeof(pkt));

    pkt.timestamp.rcv_time = 0; /* TODO: target clock cycles */

    rc = unpack_header(&pkt, tx->payload, tx->payload_len, &pos);
    if (rc)
        return rc;

    self_id = self_dev_id(s, pkt.ttype);
    if (pkt.dest_id != self_id) {
        qemu_log("RIO: WARNING: received packet not addressed to us: "
                 "dest id %x != self id %x. Processing it nevertheless.\n",
                 pkt.dest_id, self_id);
        /* spec says we process it (presumably because otherwise discovery
         * algorithm won't be able to assign device ID remotely) */
    }

    switch (pkt.ftype) {
        case RIO_FTYPE_READ:
        case RIO_FTYPE_WRITE:
        case RIO_FTYPE_STREAM_WRITE:
            /* Before unpacking map request packets need address width */
            region = resolve_map_access_region(s, &pkt);
            if (region < 0)
                break; /* deliver to SW */
            pkt.addr_width = get_in_map_region_addr_width(s, region);
            rc = unpack_body(&pkt, tx->payload, tx->payload_len, &pos);
            if (rc)
                return rc;
            return handle_map_access(s, &pkt, region);
        case RIO_FTYPE_MAINT:
            rc = unpack_body(&pkt, tx->payload, tx->payload_len, &pos);
            if (rc)
                return rc;
            switch (pkt.transaction) {
                case RIO_TRANS_MAINT_REQ_READ:
                case RIO_TRANS_MAINT_REQ_WRITE:
                    return handle_maint_access(s, &pkt);
                default:
                    break; /* leave packet unhandled */
            }
            break;
        case RIO_FTYPE_MSG:
            rc = unpack_body(&pkt, tx->payload, tx->payload_len, &pos);
            if (rc)
                return rc;
            return handle_msg(s, &pkt);
        case RIO_FTYPE_RESP:
            rc = unpack_body(&pkt, tx->payload, tx->payload_len, &pos);
            if (rc)
                return rc;
            switch (pkt.transaction) {
                case RIO_TRANS_RESP_WITH_PAYLOAD:
                case RIO_TRANS_RESP_WITHOUT_PAYLOAD: /* also DOORBELL */
                    switch (pkt.target_tid) {
                        case MAP_REQ_TID:
                            return handle_map_response(s, &pkt);
                        default:
                            /* leave unhandled: deliver to SP */
                            break;
                    }
                    break;
                case RIO_TRANS_RESP_MSG:
                    /* TODO: match by TID too? */
                    return handle_msg_response(s, &pkt);
                default:
                    /* leave unhandled: deliver to SP */
                    break;
            }
            break;
        default: /* deliver to SW via Soft Packet interface */
            break;
    }
    return deliver_to_sw(s, tx);
}

static MemTxResult map_access(BRC1RIOEndpt *s, AccessType access,
                              hwaddr addr, uint8_t *data, unsigned size,
                              Error **errp)
{
    MemTxResult ret;
    RioPkt pkt;

    if (!is_rdwr_access_supported(access, addr, size)) {
        error_setg(errp,
            "RIO: unaligned access to 0x%lx of unsupported width %u\n",
             addr, size);
        return MEMTX_ERROR;
    }

    unsigned log_nregions = ARRAY_FIELD_EX32(s->regs, IR_OMAP_CTRL, SUBREGIONS);

    uint64_t outgoing_mr_size =
        object_property_get_int(OBJECT(&s->map_mr), "size", errp);
    if (*errp) {
        return MEMTX_ERROR;
    }
    unsigned map_region_size_bits = log2_of_pow2(outgoing_mr_size) - log_nregions;
    unsigned region = addr >> map_region_size_bits;
    uint32_t reg_ctrl = s->regs[R_IR_OME_0_CTRL + region];
    MapWriteType write_type = FIELD_EX32(reg_ctrl, IR_OME_0_CTRL, WRITE_TYPE);

    if (write_type == MAP_DISABLED) {
        qemu_log("RIO: access to a disabled map region at 0x%lx\n", addr);
        return MEMTX_ERROR;
    }

    bzero(&pkt, sizeof(pkt));

    pkt.src_id = self_dev_id(s, pkt.ttype);
    pkt.dest_id = s->regs[R_IR_OME_0_DESTID + region];

    pkt.prio = FIELD_EX32(reg_ctrl, IR_OME_0_CTRL, PRIO);
    pkt.ttype = FIELD_EX32(reg_ctrl, IR_OME_0_CTRL, TTYPE);

    switch (access) {
        case ACCESS_READ:
            pkt.ftype = RIO_FTYPE_READ;
            pkt.transaction = RIO_TRANS_READ_NREAD;
            break;
        case ACCESS_WRITE:
            switch (write_type) {
                case MAP_NWRITE:
                    pkt.ftype = RIO_FTYPE_WRITE;
                    pkt.transaction = RIO_TRANS_WRITE_NWRITE;
                    break;
                case MAP_NWRITE_R:
                    pkt.ftype = RIO_FTYPE_WRITE;
                    pkt.transaction = RIO_TRANS_WRITE_NWRITE_R;
                    break;
                case MAP_SWRITE:
                    pkt.ftype = RIO_FTYPE_STREAM_WRITE;
                    /* no transaction */
                    break;
                default:
                    abort();
            }
            break;
    }

    pkt.src_tid = MAP_REQ_TID;

    pkt.addr_width =
        map_addr_size_to_bits(FIELD_EX32(reg_ctrl, IR_OME_0_CTRL, ADDR_SIZE));

    /* Refer to Figure 5 of User Guide, RIO byte address is:
     *    xamsbs[2] | extaddr[0or16or32] | dwaddr[29] | wdptr[1] | [2] */
    uint8_t xamsbs = FIELD_EX32(reg_ctrl, IR_OME_0_CTRL, XAMSBS);
    uint32_t extaddr = s->regs[R_IR_OME_0_ADDR_H + region];
    uint32_t dwaddr = s->regs[R_IR_OME_0_ADDR_L + region];

    pkt.dw_addr =
        (xamsbs << (29 + (pkt.addr_width - 3 - 2 - 29))) |
        (extaddr << 29) |
        ((dwaddr & ((1UL << (32 - map_region_size_bits)) - 1))
            << ((29 - (32 - map_region_size_bits) + 1))) |
        BYTE_ADDR_TO_DW_ADDR(addr & ((1ULL << map_region_size_bits) - 1));

    pkt.dw_offset = addr & 0b111;
    pkt.rdwr_bytes = size;

    if (access == ACCESS_WRITE) {
        memcpy((uint8_t *)pkt.payload + pkt.dw_offset, data, size);
        pkt.payload_len = div_ceil(size, sizeof(uint64_t));
    } else {
        pkt.payload_len = 0;
    }

    uint8_t crf = FIELD_EX32(reg_ctrl, IR_OME_0_CTRL, CRF);
    (void)crf; /* TODO: where is CRF used */

    MapReq *map_req = &s->map_req; /* hw supports only one outstanding req */
    assert(map_req->status == REQ_STATUS_INVALID);
    map_req->status = REQ_STATUS_OUTSTANDING;
    qemu_log("RIO: sending map request (%p)...\n", map_req);

    int rc = transmit_packet(s, &pkt);
    if (rc) {
        qemu_log("RIO: failed to transmit NREAD packet: rc %d\n", rc);
        return MEMTX_ERROR;
    }

#if 0 /* for now, impl is synchronous, so only on-chip requests supported */
    qemu_log("RIO: waiting for response to map request (%p)...\n", map_req);
    while (map_req->status == REQ_STATUS_OUTSTANDING) {
       /* yield */
    };
#endif

    /* Types that require a response */
    if (access == ACCESS_READ ||
        (access == ACCESS_WRITE && write_type == MAP_NWRITE_R)) {
        /* Since transaction implementation is synchronous, the response has
         * been processed by the callchain in transmit_packet() call above. */
        switch (map_req->status) {
            case REQ_STATUS_DONE:
                if (access == ACCESS_READ) {
                    assert(map_req->resp_len >= pkt.dw_offset + size);
                    /* TODO: malloc buffers and pass pointer around */
                    memcpy(data, map_req->resp_data + pkt.dw_offset, size);
                }
                ret = MEMTX_OK;
                break;
            case REQ_STATUS_ERROR:
            case REQ_STATUS_OUTSTANDING: /* TODO: is there timeout functionality in HW? */
                error_setg(errp,
                    "RIO: remote request for access to 0x%lx failed\n", addr);
                ret = MEMTX_ERROR;
                break;
            default:
                abort();
        }
    }
    map_req->status = REQ_STATUS_INVALID; /* release */
    return ret;
}

static MemTxResult brc1_rio_endpt_map_readb_with_attrs(void *opaque, hwaddr addr,
        uint8_t *data, unsigned size, MemTxAttrs attrs)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(opaque);
    Error *errp = NULL;
    MemTxResult result;
    result = map_access(s, ACCESS_READ, addr, data, size, &errp);
    if (errp) {
        error_report_err(errp);
    }
    return result;
}

static MemTxResult brc1_rio_endpt_map_writeb_with_attrs(void *opaque, hwaddr addr,
        const uint8_t *data, unsigned size, MemTxAttrs attrs)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(opaque);
    Error *errp = NULL;
    MemTxResult result;
    /* Cast-away const because otherwise, would need to either have an extra copy,
     * or maintain lifetime of request/response buffer beyond map_access() */
    result = map_access(s, ACCESS_WRITE, addr, (uint8_t *)data, size, &errp);
    if (errp) {
        error_report_err(errp);
    }
    return result;
}

static void brc1_rio_endpt_ir_sp_tx_ctrl_post_write(RegisterInfo *reg, uint64_t val)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(reg->opaque);

    if (s->sp_tx_state != SP_TX_STATE_IDLE) {
        qemu_log("WARN: invalid SP_TX_CTRL write: "
                "soft Packet TX State Machine not idle\n");
        return;
    }

    uint16_t octets_to_send = FIELD_EX32(val, IR_SP_TX_CTRL, OCTETS_TO_SEND);
    if (octets_to_send == 0) {
        qemu_log("WARN: invalid SP_TX_CTRL write: packet cannot be empty\n");
        return;
    }

    sp_set_tx_state(s, SP_TX_STATE_ARMED);
    /* TODO: should remaining count be updated on IDLE->ARMED or ARMED->ACTIVE? */
    ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, OCTETS_REMAINING, octets_to_send);
}

static void brc1_rio_endpt_ir_sp_tx_data_post_write(RegisterInfo *reg, uint64_t val)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(reg->opaque);
    unsigned octets_to_send, octets_remaining, octet;
    unsigned i;
    SpPkt *pkt;

    pkt = &s->sp_tx_fifo[0]; /* TODO: FIFO depth > 1 */

    switch (s->sp_tx_state) {
        case SP_TX_STATE_ARMED:
            sp_set_tx_state(s, SP_TX_STATE_ACTIVE);
            /* fall through */
        case SP_TX_STATE_ACTIVE:
            octets_to_send = ARRAY_FIELD_EX32(s->regs, IR_SP_TX_CTRL, OCTETS_TO_SEND);
            if (octets_to_send % sizeof(uint32_t) != 0) {
                qemu_log("RIO: NOTICE: invalid octets to send: %u "
                         "(must be multiple of 4 bytes)\n", octets_to_send);
                return; /* TODO: report fault? */
            }

            octets_remaining = ARRAY_FIELD_EX32(s->regs, IR_SP_TX_STAT, OCTETS_REMAINING);
            assert(octets_remaining > 0);
            octet = octets_to_send - octets_remaining;
            for (i = 0; i < sizeof(uint32_t); ++i) {
                pkt->data[octet++] = (val & 0xff000000) >> 24;
                val <<= 8;
            }
            octets_remaining -= 4;
            ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, OCTETS_REMAINING, octets_remaining);
            if (octets_remaining == 0) { /* packet completed */

                pkt->len = octets_to_send;
                ARRAY_FIELD_DP32(s->regs, IR_SP_TX_CTRL, OCTETS_TO_SEND, 0); /* TODO: spec: resets to zero here? */
                sp_set_tx_state(s, SP_TX_STATE_IDLE);

                ++s->sp_tx_fifo_count;
                ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, BUFFERS_FILLED, s->sp_tx_fifo_count);
                if (s->sp_tx_fifo_count == SP_TX_FIFO_SIZE) {
                    ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, FULL, 1);
                }

                /* For now, transmission is synchronous here, so
                 * BUFFERS_FILLED/FULL will always be zero from SW perspective. */

                RIOTx tx = {
                    .payload = (uint8_t *)&pkt->data[0],
                    .payload_len = pkt->len,
                };
                transmit_transaction(s, &tx);
                /* TODO: react to failure? */

                assert(s->sp_tx_fifo_count > 0);
                --s->sp_tx_fifo_count;
                ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, BUFFERS_FILLED, s->sp_tx_fifo_count);
                ARRAY_FIELD_DP32(s->regs, IR_SP_TX_STAT, FULL, 0);
            }
            break;
        default:
            qemu_log("WARN: invalid SP_TX_DATA write: "
                    "soft Packet TX State Machine not armed\n");
            return;
    }
}

static uint64_t brc1_rio_endpt_ir_sp_rx_data_post_read(RegisterInfo *reg, uint64_t val)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(reg->opaque);
    unsigned octets_remaining, octet;
    unsigned i;
    SpPkt *pkt;
    unsigned round_pkt_len;

    val = 0; /* IR_SP_RX_DATA is a "virtual" register, doesn't store data */

    if (s->sp_rx_fifo_count == 0) {
        qemu_log("WARN: invalid SP_RX_DATA read: rx queue is empty\n");
        return val;
    }
    pkt = &s->sp_rx_fifo[0]; /* TODO: FIFO depth > 1 */
    round_pkt_len = ALIGN(pkt->len, 2); /* log2(sizeof(uint32_t)) */

    switch (s->sp_rx_state) {
        case SP_RX_STATE_IDLE:
            octets_remaining = round_pkt_len;
            assert(octets_remaining > 0);
            assert(octets_remaining % sizeof(uint32_t) == 0);
            sp_set_rx_state(s, SP_RX_STATE_ACTIVE);
            break;
        case SP_RX_STATE_ACTIVE:
            octets_remaining = ARRAY_FIELD_EX32(s->regs, IR_SP_RX_STAT, OCTETS_REMAINING);
            break;
    }

    if (octets_remaining == 0) {
        qemu_log("WARN: invalid SP_RX_DATA read: rx queue is empty\n");
        return val;
    }

    assert(round_pkt_len >= octets_remaining);
    octet = round_pkt_len - octets_remaining;
    /* Overwrite return value 'val'; don't ever store anything in
     * the actual data register s->regs[IR_SP_RX_STAT] */
    val = 0;
    for (i = 0; i < sizeof(uint32_t) && octets_remaining; ++i) {
        val |= (uint32_t)pkt->data[octet + i] << (32 - (i + 1) * 8);
        assert(octets_remaining > 0);
        --octets_remaining;
    }
    assert(octets_remaining % sizeof(uint32_t) == 0);
    ARRAY_FIELD_DP32(s->regs, IR_SP_RX_STAT, OCTETS_REMAINING, octets_remaining);

    if (octets_remaining == 0) {
        assert(s->sp_rx_fifo_count > 0);
        --s->sp_rx_fifo_count;
        ARRAY_FIELD_DP32(s->regs, IR_SP_RX_STAT, BUFFERS_FILLED, s->sp_rx_fifo_count);
        ARRAY_FIELD_DP32(s->regs, IR_SP_RX_STAT, FULL, 0);
        sp_set_rx_state(s, SP_RX_STATE_IDLE);
    }
    return val;
}

static void brc1_rio_endpt_ir_msg_init_ps_descr_fifo_post_write(RegisterInfo *reg, uint64_t val)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(reg->opaque);
    int rc;

    /* Software responsible for first writing LO than HI */
    uint64_t desc_addr =
        ((uint64_t)s->regs[R_IR_MSG_INIT_PS_DESCR_FIFO_H] << 32) |
        s->regs[R_IR_MSG_INIT_PS_DESCR_FIFO_L];

    if (!desc_addr) {
        qemu_log("RIO: NOTICE: TX msg descriptor is null\n");
        /* TODO: report failure somehow? */
        return;
    }

    rc = transmit_msg(s, desc_addr, MSG_DESC_INITIATOR_PS);
    if (rc) {
        /* TODO: report failure somehow? */
        return;
    }
}

static void brc1_rio_endpt_ir_msg_trgt_descr_fifo_post_write(RegisterInfo *reg, uint64_t val)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(reg->opaque);
    int rc;

    /* Software responsible for first writing LO than HI */
    uint64_t desc_addr = s->regs[R_IR_MSG_TRGT_DESCR_FIFO_H];
    desc_addr <<= 32;
    desc_addr |= s->regs[R_IR_MSG_TRGT_DESCR_FIFO_L];

    if (!desc_addr) {
        qemu_log("ERROR: RIO: receive message descriptor NULL, ignored\n");
        return;
    }

    rc = msg_rx_fifo_enqueue(s, desc_addr);
    if (rc) {
        qemu_log("ERROR: RIO: receive message descriptor FIFO overflow:"
                 "rc %x\n", rc);
        return;
    }
}

/* TODO: mark read-only fields */
static const RegisterAccessInfo brc1_rio_endpt_regs_info[] = {
    {
        .name = "DEV_ID",  .addr = A_DEV_ID,
        .reset = 0x44332211, /* TODO: check on real HW */
        .rsvd = 0x0,
    },{
        .name = "LCS_BA0",  .addr = A_LCS_BA0,
        .reset = 0x0,
        .rsvd = 0x80000000,
    },{
        .name = "LCS_BA1",  .addr = A_LCS_BA1,
        .reset = 0x0,
        .rsvd = 0x0,
    },{
        .name = "B_DEV_ID",  .addr = A_B_DEV_ID,
        .reset = 0x0,
        .rsvd = 0x0,
    },{
        .name = "COMP_TAG",  .addr = A_COMP_TAG,
        .reset = 0x0,
        .rsvd = 0x0,
    },{
        .name = "IR_SP_TX_CTRL",  .addr = A_IR_SP_TX_CTRL,
        .reset = 0x0,
        .rsvd = 0x0000ffff,
        .post_write = brc1_rio_endpt_ir_sp_tx_ctrl_post_write,
    },{
        .name = "IR_SP_TX_STAT",  .addr = A_IR_SP_TX_STAT,
        .reset = 0x0,
        .ro = ~0,
        .rsvd = 0x7f << (32 - 20 - 7),
    },{
        .name = "IR_SP_TX_DATA",  .addr = A_IR_SP_TX_DATA,
        .reset = 0x0,
        .rsvd = 0x0,
        .post_write = brc1_rio_endpt_ir_sp_tx_data_post_write,
    },{
        .name = "IR_SP_RX_CTRL",  .addr = A_IR_SP_RX_CTRL,
        .reset = 0x0,
        .rsvd = 0x0000ffff,
    },{
        .name = "IR_SP_RX_STAT",  .addr = A_IR_SP_RX_STAT,
        .reset = 0x0,
        .ro = ~0,
        .rsvd = 0x7f << (32 - 20 - 7),
    },{
        .name = "IR_SP_RX_DATA",  .addr = A_IR_SP_RX_DATA,
        .reset = 0x0,
        .ro = ~0,
        .rsvd = 0x0,
        .post_read = brc1_rio_endpt_ir_sp_rx_data_post_read,
    },{
        .name = "IR_MSG_CTRL",  .addr = A_IR_MSG_CTRL,
        .reset = 0x0,
        .rsvd = ~0,
    },{
        .name = "IR_MSG_INIT_PS_STAT",  .addr = A_IR_MSG_INIT_PS_STAT,
        .reset = (1 << R_IR_MSG_INIT_PS_STAT_IDLE_SHIFT) |
                 (MSG_PS_MAX_DESCRIPTORS << R_IR_MSG_INIT_PS_STAT_MAX_DESCRIPTORS_SHIFT),
        .rsvd = (0x7 << (32 - 1 - 3)) | (0xfffff << (32 - 12 - 20)),
    },{
        .name = "IR_MSG_INIT_PS_DESCR_FIFO_L",  .addr = A_IR_MSG_INIT_PS_DESCR_FIFO_L,
        .reset = 0x0,
        .post_write = brc1_rio_endpt_ir_msg_init_ps_descr_fifo_post_write,
    },{
        .name = "IR_MSG_INIT_PS_DESCR_FIFO_H",  .addr = A_IR_MSG_INIT_PS_DESCR_FIFO_H,
        .reset = 0x0,
    },{
        .name = "IR_MSG_TRGT_STAT",  .addr = A_IR_MSG_TRGT_STAT,
        .reset = (1 << R_IR_MSG_TRGT_STAT_IDLE_SHIFT) |
                 (MSG_TRGT_MAX_DESCRIPTORS << R_IR_MSG_TRGT_STAT_MAX_DESCRIPTORS_SHIFT),
        .rsvd = (0x7 << (32 - 1 - 3)) | (0xfffff << (32 - 12 - 20)),
    },{
        .name = "IR_MSG_TRGT_DESCR_FIFO_L",  .addr = A_IR_MSG_TRGT_DESCR_FIFO_L,
        .reset = 0x0,
        .post_write = brc1_rio_endpt_ir_msg_trgt_descr_fifo_post_write,
    },{
        .name = "IR_MSG_TRGT_DESCR_FIFO_H",  .addr = A_IR_MSG_TRGT_DESCR_FIFO_H,
        .reset = 0x0,
    },{
        .name = "IR_OMAP_CTRL",  .addr = A_IR_OMAP_CTRL,
        .reset = 0x0,
        .rsvd = 0x8fffffff,
    },{
        .name = "IR_OME_0_CTRL",  .addr = A_IR_OME_0_CTRL,
        .reset = 0x0,
        .rsvd = 0x001fffff,
    },{
        .name = "IR_OME_0_DESTID",  .addr = A_IR_OME_0_DESTID,
        .reset = 0x0,
    },{
        .name = "IR_OME_0_ADDR_H",  .addr = A_IR_OME_0_ADDR_H,
        .reset = 0x0,
    },{
        .name = "IR_OME_0_ADDR_L",  .addr = A_IR_OME_0_ADDR_L,
        .reset = 0x0,
        .rsvd = 0x0003ffff,
    },

#define MAP_OUT_REGS(i) \
    { .name = "IR_OME_" #i "_CTRL", .addr = A_IR_OME_0_CTRL + i * 4, \
        .reset = 0x0, .rsvd = 0x001fffff }, \
    { .name = "IR_OME_" #i "_DESTID", .addr = A_IR_OME_0_DESTID + i * 4, \
        .reset = 0x0 }, \
    { .name = "IR_OME_" #i "_ADDR_H", .addr = A_IR_OME_0_ADDR_H + i * 4, \
        .reset = 0x0 }, \
    { .name = "IR_OME_" #i "_ADDR_L", .addr = A_IR_OME_0_ADDR_L + i * 4, \
        .reset = 0x0, .rsvd = 0x0003ffff } \

    MAP_OUT_REGS(0),  MAP_OUT_REGS(1),  MAP_OUT_REGS(2),  MAP_OUT_REGS(3),
    MAP_OUT_REGS(4),  MAP_OUT_REGS(5),  MAP_OUT_REGS(6),  MAP_OUT_REGS(7),
    MAP_OUT_REGS(8),  MAP_OUT_REGS(9),  MAP_OUT_REGS(10), MAP_OUT_REGS(11),
    MAP_OUT_REGS(12), MAP_OUT_REGS(13), MAP_OUT_REGS(14), MAP_OUT_REGS(15),
    MAP_OUT_REGS(16), MAP_OUT_REGS(17), MAP_OUT_REGS(18), MAP_OUT_REGS(19),
    MAP_OUT_REGS(20), MAP_OUT_REGS(21), MAP_OUT_REGS(22), MAP_OUT_REGS(23),
    MAP_OUT_REGS(24), MAP_OUT_REGS(25), MAP_OUT_REGS(26), MAP_OUT_REGS(27),
    MAP_OUT_REGS(28), MAP_OUT_REGS(29), MAP_OUT_REGS(30), MAP_OUT_REGS(31),
    MAP_OUT_REGS(32), MAP_OUT_REGS(33), MAP_OUT_REGS(34), MAP_OUT_REGS(35),
    MAP_OUT_REGS(36), MAP_OUT_REGS(37), MAP_OUT_REGS(37), MAP_OUT_REGS(39),
    MAP_OUT_REGS(40), MAP_OUT_REGS(41), MAP_OUT_REGS(42), MAP_OUT_REGS(43),
    MAP_OUT_REGS(44), MAP_OUT_REGS(45), MAP_OUT_REGS(46), MAP_OUT_REGS(47),
    MAP_OUT_REGS(48), MAP_OUT_REGS(49), MAP_OUT_REGS(50), MAP_OUT_REGS(51),
    MAP_OUT_REGS(52), MAP_OUT_REGS(53), MAP_OUT_REGS(54), MAP_OUT_REGS(55),
    MAP_OUT_REGS(56), MAP_OUT_REGS(57), MAP_OUT_REGS(58), MAP_OUT_REGS(59),
    MAP_OUT_REGS(60), MAP_OUT_REGS(61), MAP_OUT_REGS(62), MAP_OUT_REGS(63),

    {
        .name = "IR_IMAP_CTRL",  .addr = A_IR_IMAP_CTRL,
        .reset = 0x0,
        .rsvd = 0x8fffffff,
    },

#define MAP_IN_REGS(i) \
    { .name = "IR_IME_" #i "_CTRL", .addr = A_IR_IME_0_CTRL + i * 4, \
        .reset = 0x0, .rsvd = 0x3fffffff }, \
    { .name = "IR_IME_" #i "_SRCID", .addr = A_IR_IME_0_SRCID + i * 4, \
        .reset = 0x0 }, \
    { .name = "IR_IME_" #i "_SRCIDM", .addr = A_IR_IME_0_SRCIDM + i * 4, \
        .reset = 0x0 }, \
    { .name = "IR_IME_" #i "_ADDR_H", .addr = A_IR_IME_0_ADDR_H + i * 4, \
        .reset = 0x0 }, \
    { .name = "IR_IME_" #i "_ADDR_L", .addr = A_IR_IME_0_ADDR_L + i * 4, \
        .reset = 0x0 } \

    MAP_IN_REGS(0),  MAP_IN_REGS(1),  MAP_IN_REGS(2),  MAP_IN_REGS(3),
    MAP_IN_REGS(4),  MAP_IN_REGS(5),  MAP_IN_REGS(6),  MAP_IN_REGS(7),
    MAP_IN_REGS(8),  MAP_IN_REGS(9),  MAP_IN_REGS(10), MAP_IN_REGS(11),
    MAP_IN_REGS(12), MAP_IN_REGS(13), MAP_IN_REGS(14), MAP_IN_REGS(15),
    MAP_IN_REGS(16), MAP_IN_REGS(17), MAP_IN_REGS(18), MAP_IN_REGS(19),
    MAP_IN_REGS(20), MAP_IN_REGS(21), MAP_IN_REGS(22), MAP_IN_REGS(23),
    MAP_IN_REGS(24), MAP_IN_REGS(25), MAP_IN_REGS(26), MAP_IN_REGS(27),
    MAP_IN_REGS(28), MAP_IN_REGS(29), MAP_IN_REGS(30), MAP_IN_REGS(31),
    MAP_IN_REGS(32), MAP_IN_REGS(33), MAP_IN_REGS(34), MAP_IN_REGS(35),
    MAP_IN_REGS(36), MAP_IN_REGS(37), MAP_IN_REGS(37), MAP_IN_REGS(39),
    MAP_IN_REGS(40), MAP_IN_REGS(41), MAP_IN_REGS(42), MAP_IN_REGS(43),
    MAP_IN_REGS(44), MAP_IN_REGS(45), MAP_IN_REGS(46), MAP_IN_REGS(47),
    MAP_IN_REGS(48), MAP_IN_REGS(49), MAP_IN_REGS(50), MAP_IN_REGS(51),
    MAP_IN_REGS(52), MAP_IN_REGS(53), MAP_IN_REGS(54), MAP_IN_REGS(55),
    MAP_IN_REGS(56), MAP_IN_REGS(57), MAP_IN_REGS(58), MAP_IN_REGS(59),
    MAP_IN_REGS(60), MAP_IN_REGS(61), MAP_IN_REGS(62), MAP_IN_REGS(63),
};

static const MemoryRegionOps brc1_rio_endpt_ops = {
    .read = brc1_rio_endpt_read,
    .write = brc1_rio_endpt_write,
    .endianness = DEVICE_BIG_ENDIAN,
    .valid = {
        .min_access_size = 4,
        .max_access_size = 4,
    },
};

/* rdsize/wrsize for NREAD/NWRITE (Spec Tables 4-3, 4-4) */
#define MIN_ACCESS_SIZE   1  /* TODO: test size < 4 */
#define MAX_ACCESS_SIZE 256

static const MemoryRegionOps brc1_rio_endpt_map_ops = {
    .readb_with_attrs = brc1_rio_endpt_map_readb_with_attrs,
    .writeb_with_attrs = brc1_rio_endpt_map_writeb_with_attrs,
    .endianness = DEVICE_BIG_ENDIAN,
    .valid = {
        .min_access_size = MIN_ACCESS_SIZE,
        .max_access_size = MAX_ACCESS_SIZE,
    },
    .impl = {
        .min_access_size = MIN_ACCESS_SIZE,
        .max_access_size = MAX_ACCESS_SIZE,
    },
};


static void brc1_rio_endpt_reset(DeviceState *dev)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(dev);
    unsigned int i;

    for (i = 0; i < ARRAY_SIZE(s->regs_info); ++i) {
        register_reset(&s->regs_info[i]);
    }

    sp_set_tx_state(s, SP_TX_STATE_IDLE);
    sp_set_rx_state(s, SP_TX_STATE_IDLE);
}

static void brc1_rio_endpt_realize(DeviceState *dev, Error **errp)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(dev);
    unsigned int i;

    for (i = 0; i < ARRAY_SIZE(brc1_rio_endpt_regs_info); ++i) {
        RegisterInfo *r = &s->regs_info[brc1_rio_endpt_regs_info[i].addr / 4];

        *r = (RegisterInfo) {
            .data = (uint8_t *)&s->regs[brc1_rio_endpt_regs_info[i].addr / 4],
            .data_size = sizeof(uint32_t),
            .access = &brc1_rio_endpt_regs_info[i],
            .opaque = s,
        };
    }

    if (!s->dma_mr) {
        error_setg(errp, "'dma' property in device tree node not set");
        return;
    }
    s->dma_as = address_space_init_shareable(s->dma_mr, NULL);
    if (!s->dma_as) {
        error_setg(errp, "failed to init DMA address space");
        return;
    }
}

static void brc1_rio_endpt_init(Object *obj)
{
    BRC1RIOEndpt *s = BRC1_RIO_ENDPT(obj);
    SysBusDevice *sbd = SYS_BUS_DEVICE(obj);

    /* Region size is not REG_MAX, because want whole range defined by spec. */
    assert(REG_MAX <= IOMEM_REGION_SIZE);
    memory_region_init_io(&s->iomem, obj, &brc1_rio_endpt_ops,
                          s, TYPE_BRC1_RIO_ENDPT, IOMEM_REGION_SIZE);
    sysbus_init_mmio(sbd, &s->iomem);

    memory_region_init_io(&s->map_mr, OBJECT(obj), &brc1_rio_endpt_map_ops,
                          sbd, TYPE_BRC1_RIO_ENDPT "-outgoing",
                          /* size: set by reg prop in DT node */ 0);
    sysbus_init_mmio(sbd, &s->map_mr);

    sysbus_init_irq(SYS_BUS_DEVICE(s), &s->event_irq);
    sysbus_init_irq(SYS_BUS_DEVICE(s), &s->msg_tx_irq);
    sysbus_init_irq(SYS_BUS_DEVICE(s), &s->msg_rx_irq);
}

static const VMStateDescription vmstate_brc1_rio_endpt = {
    .name = TYPE_BRC1_RIO_ENDPT,
    .version_id = 1,
    .minimum_version_id = 1,
    .minimum_version_id_old = 1,
    .fields = (VMStateField[]) {
        VMSTATE_UINT32_ARRAY(regs, BRC1RIOEndpt, REG_MAX),
        VMSTATE_END_OF_LIST(),
    }
};

static Property brc1_rio_endpt_properties[] = {
#if 0
    DEFINE_PROP_LINK("port", BRC1RIOEndpt, port,
                     TYPE_BRC1_RIO_PORT, RIOPort *),
#else
    DEFINE_PROP_LINK("switch", BRC1RIOEndpt, rio_switch,
                     TYPE_SM_RIO_SWITCH, SMRIOSwitch *),
    DEFINE_PROP_UINT8("port-idx", BRC1RIOEndpt, rio_switch_port_idx, 0),
#endif
    DEFINE_PROP_LINK("dma", BRC1RIOEndpt, dma_mr,
                     TYPE_MEMORY_REGION, MemoryRegion *),
    DEFINE_PROP_END_OF_LIST(),
};

static void brc1_rio_endpt_class_init(ObjectClass *klass, void *data)
{
    DeviceClass *dc = DEVICE_CLASS(klass);

    dc->reset = brc1_rio_endpt_reset;
    dc->realize = brc1_rio_endpt_realize;
    dc->props = brc1_rio_endpt_properties;
    dc->vmsd = &vmstate_brc1_rio_endpt;
}

static const TypeInfo brc1_rio_endpt_info = {
    .name          = TYPE_BRC1_RIO_ENDPT,
    .parent        = TYPE_SYS_BUS_DEVICE,
    .instance_size = sizeof(BRC1RIOEndpt),
    .class_init    = brc1_rio_endpt_class_init,
    .instance_init = brc1_rio_endpt_init,
};

static void brc1_rio_endpt_register_types(void)
{
    type_register_static(&brc1_rio_endpt_info);
}

type_init(brc1_rio_endpt_register_types)
